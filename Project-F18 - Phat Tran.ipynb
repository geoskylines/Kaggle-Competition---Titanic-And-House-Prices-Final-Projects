{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"Project-F18.ipynb","version":"0.3.2","provenance":[{"file_id":"17UifMYYQLillK0T5B6bS0dJkdcrTYVi3","timestamp":1544142671109}]},"kernelspec":{"name":"python3","display_name":"Python 3"}},"cells":[{"metadata":{"id":"ldN7ZC2z9SYI","colab_type":"text"},"cell_type":"markdown","source":["#IT for Business Analytics - Project#"]},{"metadata":{"id":"pEmaMiX1C5Vt","colab_type":"text"},"cell_type":"markdown","source":["**Name:** "]},{"metadata":{"id":"HF3YUhxBET__","colab_type":"text"},"cell_type":"markdown","source":["![alt text](https://storage.googleapis.com/kaggle-competitions/kaggle/5407/media/housesbanner.png)\n","## Project Description\n","The project is the [House Prices: Advanced Regression Techniques](https://www.kaggle.com/c/house-prices-advanced-regression-techniques) competition on Kaggle. With 79 explanatory variables describing (almost) every aspect of residential homes in Ames, Iowa, this competition challenges you to predict the final price of each home. Your goal is to get the highest ranking on Kaggle within the class. However, while doing this, you need to clearly explain what you are doing between your code chunks. Basically, you should tell a story of your Kaggle score. \n","\n","Evaluation metric is RMSE - lowest score will get the highest ranking.\n","\n","Do not leave this project to last day. You can rush and finish it quickly but you will not get a good grade. Getting a high score on Kaggle requires a good amount of work. Keep in mind that **you can submit only 5 entries per day.**\n","\n","\n","## Kaggle \n","[from class notes on supervised learning]\n","\n","Kaggle, which is owned by Google, is an online community of data scientist. The main attraction of Kaggle is the machine learning competitions it hosts. Some of these are for education for purposes, and others are for recruitment and prizes. \n","\n","Go to [kaggle.com](https://www.kaggle.com/) and register. You can use your Binghamton email, personal email, or existing social/website accounts (Google, Yahoo, Facebook). Once created, your username cannot be changed. However, your display name can be changed anytime from your profile. \n","\n",">  Your username can be anything you prefer, but your display name must start with **amy-**. \n","\n","After amy- you can have anything you prefer as part of your username: for instance, amy-aybu. You can choose to have your name or username after amy- however, remember that the class project is a competition and if you have your name or Binghamton username, your ranking will not be anonymous. \n","\n","As a reminder, the project grade will depend on your competition ranking. Since everyone in the class will have a display name starting with amy-, after you submit your entry, you can see where you stand in the class by searching amy- on the leaderboard. If everyone chooses a random display name after amy-, we can keep the standing confidential. Keeping the ranking confidential is not essential, however, what is more important is knowing where you stand in the ranking compared to the class during the project submission since it will indicate whether you need to put more effort.\n","\n","The way Kaggle competitions work is you train a model with the given `train` dataset and make predictions using the given `test` dataset, and your submission score is based on the \"accuracy\" of your predictions. The metric to measure depends on the competition.\n","\n"," \n","\n","## Google Colaboratoty\n","\n","Go to [Google Colab's website](https://colab.research.google.com/notebooks/welcome.ipynb) and create a new notebook from File - New Python 3 notebook. You need to sign in with a Google account. Use your Binghamton account details so you can share it with me easier at the end of the project.\n","\n","There are two types of cells in the Colab notebook: code and text. Text cell is for text purposes, where you explain your code. Code cell is for your code - Python 3. It is very straight-forward but just in case, below are some basic instructions from Google Colab website.\n","\n","---\n","**Code cells**  \n","Once the toolbar button indicates connected (use hosted runtime), click in the cell to select it and execute the contents in the following ways:\n","\n","* Click the Play icon in the left gutter of the cell;\n","* Type Cmd/Ctrl+Enter to run the cell in place;\n","* Type Shift+Enter to run the cell and move focus to the next cell (adding one if none exists); or\n","* Type Alt+Enter to run the cell and insert a new code cell immediately below it.\n","There are additional options for running some or all cells in the Runtime menu.\n","\n","**Text cells**  \n","This is a text cell. You can double-click to edit this cell. Text cells use markdown syntax. To learn more, see our [markdown guide](https://colab.research.google.com/notebooks/markdown_guide.ipynb).\n","\n","For project purposes, you don't need to format your text cell but make sure you have some logical separations between code and text cell, where a text cell explains what the code cell underneath it does. \n","\n","**Adding and moving cells**  \n","You can add new cells by using the + CODE and + TEXT buttons that show when you hover between cells. These buttons are also in the toolbar above the notebook where they can be used to add a cell below the currently selected cell.\n","\n","You can move a cell by selecting it and clicking Cell Up or Cell Down in the top toolbar.\n","\n","---\n","\n","When your Colab notebook is inactive for a long time, your session automatically ends. You can always re-connect to the hosted runtime, but you need to re-run all your code. Once the session is terminated, libraries, variables, etc. are resetted (gone!) since every new session connects to a new virtual machine.\n","\n","## Project Setup\n","You can make a copy of this notebook and save it to your Binghamton Google Drive. All your answers will be on your copy of this notebook: Part 1 with answers to concepts, Part 2 code for the hands-on part.\n","\n","\n","## Helpful DataCamp courses\n","The project is on building regression based machine learning models. You completed various chapters on DataCamp covering most of the algorithms you are likely to use. Below is a list of the courses/chapters you may want to go back to refresh your knowledge. You can always re-watch the videos and look at the slides for quick tips. To download chapter slides on DataCamp, start the chapter, and click on the  pdf icon on the top right.\n","* Supervised Learning with scikit-learn: chapter 2\n","* Extreme Gradient Boosting with XGBoost: chapter 2, 3, 4 (*This method is not covered in the class*)\n","* Machine Learning with Tree-Based Models: all chapters\n","\n","<br/>\n","<br/>\n","\n","---\n","**Don't forget to read the submission and grading guidelines at the end of the notebook**\n","\n","---\n","<br/>\n","<br/>"]},{"metadata":{"id":"ZGzxpX1WKhMC","colab_type":"text"},"cell_type":"markdown","source":["# Part 1 - Machine Learning Concepts"]},{"metadata":{"id":"rF-vU62C9SHl","colab_type":"text"},"cell_type":"markdown","source":["## Questions\n","Describe the following concepts in the context of machine learning:\n","1. Supervised vs. unsupervised learning\n","2. Model interpretability vs. accuracy\n","3. Bias vs. variance\n","4. Regression vs. classification \n","5. Bootstraping vs. cross-validation\n","6. Overfitting vs. underfitting\n"]},{"metadata":{"id":"zQK7loSVKI1U","colab_type":"text"},"cell_type":"markdown","source":["## Answers\n","Write your answers below.\n","\n","**Part I:\n","Questions\n","Describe the following concepts in the context of machine learning:**\n","\n","**Supervised vs. unsupervised learning**\n","\n","\tSupervised learning means that the user or programmer teaches the machine using data that are already labeled.  Supervised learning usually deals with two categories of algorithms such as Classification and Regression.  Classification within the data set are usually output variables.  Lets say a dataset consisting of different fruits and the classification would be considered the output categories such as “Green” or “Yellow” or “Fresh” or “Rotten”.  Regression in the dataset shows real value of outputs such as “dollars” or “size” or “weight”.  Supervised learning means that the user or programmer has to directly teach the machine to identify the dataset between inputs and outputs.  The machine itself cannot analysis the dataset without any guidance such as Unsupervised learning.\n","\tUnsupervised learning means that the user or programmer has to teach the machine with information that are not already classified or labeled in the dataset.  The machine learning from the programmer will therefore recognized the information without any guidance from the user or programmers in further process of analyzing the dataset.  Unsupervised learning typically involved categories such as Clustering and Association.  Clustering means that the dataset has certain grouping involved in the dataset such as grouping all “sales purchasing transactions together”.  Association means that the dataset has certain rules that connect these grouping together in the dataset.  The machine can identify these relationships in the dataset and analysis the data without any guidance.\n","\n","Work-Cited MLA Style\n","\n","* Soni,Devin. “Supervised vs. Unsupervised Learning – Towards Data Science.” Towards Data Science, Towards Data Science, 22 Mar. 2018, https://towardsdatascience.com/supervised-vs-unsupervised-learning-14f68e32ea8d\n","\n","* GeeksforGeeks. “Supervised and Unsupervised learning.” GeeksforGeeks, https://www.geeksforgeeks.org/supervised-unsupervised-learning/\n","\n","**Model interpretability vs. accuracy**\n","\n","\tInterpretability meaning how the accuracy is explained in the dataset toward the programmer or user.  The dataset might have Accuracy but without any good Model interpretability would give no value toward the user or programmer to understand the information within the dataset.  Dataset that have fewer parameters are better understand and interpretability.  A good example of Model interpretability would be a “Decision Tree”, which breaks down the structure of the dataset into parts.  This would make the user or programmer understand the information within the dataset better. \n","\tAccuracy meaning how the output from of the prediction are correct and have few errors.  Accuracy are usually predicted values in measurements in the outcome.  Accuracy doesn’t interpret the outcomes toward the users or programmers.  Accuracy just gives a straight forward measurement of how the algorithms runs and process the dataset.  A dataset that get bigger with more information would result in less interpretability.  As the dataset gets bigger with more information, this would result in more complexity of the Model.  Therefore, the dataset gets very difficult to interpret toward the user or programmer.\n","\n","Work-Cited MLA Style\n","\n","* Brownlee, Jason. “Model Prediction Accuracy Versus Interpretation in Machine Learning.” Machine Learning Mastery, 1 Aug. 2014, https://machinelearningmastery.com/model-prediction-versus-interpretation-in-machine-learning/\n","\n","**Bias vs. variance**\n","\n","\tBias are assumptions made toward the dataset model to keep the parametric between certain information in the dataset easier to understand and quicker to gather.  Two topics of bias would consist of “Low Bias” and “High Bias”.  “Low Bias” have less assumptions about information in the dataset and “High Bias” have larger assumptions about the information in the dataset.  “Low Bias” assumptions would consist of Decision Tress, k-Nearest Neighbors and Support Vector Machines.  “High Bias” assumptions would consist of Linear Regression, Linear Discriminant Analysis and Logistic Regression.\n","\tVariance are estimation of amount of a target function and how that target function would change in a predictable direction.  Variance in a dataset also shows the accurately of the output and dataset.  Variance consist of two categories such as “Low Variance” and “High Variance”.  “Low Variance” are small estimation of the target functions relatively dealing with the changes in the dataset.  “High Variance” are large estimation of the target functions that are relatively dealing with the direction of the dataset.  “Low Variance” examples would be Linear Regression, Linear Discriminant Analysis and Logistic Regression.  “High Variance” examples would be Decision Trees, k-nearest Neighbors and Support Vector Machines.\n","\tAn important concept between Bias and Variance would be that increasing the bias would create a decrease in the variance.  An increase in the variance would result in a decrease in the bias.  This is the relationship that are between Bias and Variances.  Bias and Variances play a key role in predicting the performance in the dataset and behavior of the machine learning algorithms.  Bias are assumptions that are simplified to make predictions on the dataset and Variance is the estimated amount that a target function would change in direction for the dataset.\n","\n","Work-Cited MLA Style\n","\n","* Brownlee, Jason. “Model Prediction Accuracy Versus Interpretation in Machine Learning.” Machine Learning Mastery, 1 Aug. 2014, https://machinelearningmastery.com/gentle-introduction-to-the-bias-variance-trade-off-in-machine-learning/\n","\n","**Regression vs. classification**\n","\n","\tClassification are labels or categories in a dataset that involve (X) and (Y) inputs and outputs.  Classification are used to quickly sort the datasets and make predicted outputs of values within the dataset.  Classifications predicts the discrete labels or categories within the dataset.  Classifications predictions are used to predict the accuracy of outputs and inputs within the dataset.  Regressions predictions are not able to complete these predictions in the dataset such as Classifications. A good used of classifications would be binary classification such as “Yes” or “No” outcome in a survey to customer’s if they like a product or not.  This binary classification makes it very easy and fast to process the dataset.\n","\tRegression are usually mapping functions within the dataset of (X) and (Y) inputs and outputs.  Regression usually involve real time value such as “dollar value” or “weight value”.  These values are usually integer or floating value points in the dataset.  Regression are used to predict quantity and estimations within the set.  Regressions have the ability to evaluate predictions of square roots mean squared errors and Classifications don’t have the ability to evaluate these functions.  Regression help evaluate the dataset and explain the impact of input and output within the dataset.\n","\n","Work-Cited MLA Style\n","\n","* Brownlee, Jason. “Difference Between Classiciation and Regression in Machine Learning.” Machine learning Mastery, 11 Dec. 2017, https://machinelearningmastery.com/classification-versus-regression-in-machine-learning/\n","\n","* Castle, Nikki. “Regression vs. Classification Algorithms. “ Oracle DataScience.com, 8 Mar. 2018, https://www.datascience.com/blog/regression-and-classification-machine-learning-algorithms\n","\n","**Bootstraping vs. cross-validation**\n","\n","\tBootstrapping are used to validate the prediction within the dataset and help make estimations that concern with the bias and variance of the dataset.  Bootstrapping would collect the chosen values within the dataset and these values could be tested for further predictions.  Bootstrapping are used for statistical validations without using existing formulas for the dataset.  Bootstrapping are used to analysis the datasets sample size in confidence interval such as within 95% confidence of the Variance.  Bootstrapping can estimate the median weight of uncertainty around the gather values of the dataset information.  If parametric of certain group of values of the data set are questionable.  Bootstrapping can test for these parametric errors.\n","\tCross Validation is done to validate the dataset’s model for performance and typically splits the dataset into numerous parts during the process.  The number of parts through Cross Validation are up to the user’s choice in processing the dataset.  If the user or programmer splits the Cross Validation into too many parts, this would increase the Variance and decrease the Bias.  If the Bias increases, therefore the Variance would decrease as a result.  The three steps in Cross Valuation method are “Reserve some portion of sample data-set”, “Using the rest data-set train the model”, and “test the model using the reserve portion of the dataset”.  Through these three methods are used to validate, analysis, or test values collected within the dataset.\n","\n","Work-Cited MLA Style\n","\n","* Aly, Mazen, “What is the difference between bootstrapping and cross validation?” Quora, 29th Sep. 2016, https://www.quora.com/What-is-the-difference-between-bootstrapping-and-cross-validation\n","\n","* Albright, Jeremy, “What is the Bootstrap?” Methods, 26th Feb. 2015, https://www.methodsconsultants.com/tutorial/what-is-the-bootstrap/\n","\n","* Sharma, Abhishek, “Cross Validation in Machine Learning”, GeeksforGeeks, https://www.geeksforgeeks.org/cross-validation-machine-learning/\n","\n","**Overfitting vs. underfitting**\n","\n","\tOverfitting means overloading too much data information into the dataset.  The model of the machine learning will start to learn inaccurate data entries inside the dataset.  This will result in the model to unable to categorized or organized any computations correctly for any testing of the dataset information.  Two main causes of overfitting would consist of non-parametric and non-linear methods.  These methods give more flexibility for users or programmers to build the model inside the dataset but causes Overfitting issues.\n","\tUnderfitting means that the model of the machine learning cannot be able to gather the information within the trend of the dataset.  Underfitting results in inaccuracy of the dataset.  The model might have too minimum of information inside the dataset to perform correctly to machine learning algorithms.  This would result in inaccuracy of predictions or testing of the dataset information.  This typically occurs when the user or programmer tries to build a linear model using non-linear datasets.  Underfitting can be prevented by simply adding more information toward the dataset.\n","\n","Work-Cited MLA Style\n","\n","* Nautiyal, Dewang, “Underfitting and Overfitting in Machine Learning” GeeksforGeeks, https://www.geeksforgeeks.org/underfitting-and-overfitting-in-machine-learning/\n","\n","\n"]},{"metadata":{"id":"PvK2UHuPTWEG","colab_type":"text"},"cell_type":"markdown","source":["# Part 2 - Hands-on\n","\n","## Important notes\n","\n","**Code sharing**  \n","Sharing is defined as copying or looking at another code. You are not allowed to\n","* share your code/solutions with other students,\n","* seek for code/solutions from other students.\n","\n","Please report any code sharing violation to the instructor. Consider the fact that the assignments will have many correct solutions. Any similarity in the order, syntax, variable names, mistakes, typos, and other small details are proofs of code sharing. While you are allowed to discuss homeworks, assignments, and the project with other students, you are expected to write your own code.\n","\n","\n","**Use of Kaggle Kernels**   \n","You can look at the available kernels on Kaggle, read the discussions, or search for examples on the Internet. This will be helpful and may speed up your project. However, you are not allowed to copy and use code available online (Kaggle or elsewhere).\n","\n","\n","## Tips\n","**Explanatory Data Analysis**  \n","Familiarize yourself with the dataset. Run some simple descriptives and graphs to find out more about the variables. Keep some of the good ones for your submission. Delete the ones that doesn't give any information.\n","\n","**Missing Data**\n","Look at the missing variables and make a plan to address them if necessary. Make sure you address the missing data in the `test` dataset as well.\n","\n","**Feature Engineering**   \n","You can build your model with existing variables, but you should also create new variables from the existing variables (e.g., you can create new categorical variable by grouping ages of houses). If you create new variables in your `train` dataset (which is a strongly suggested), make sure to create them in your `test` dataset as well. You can check Titanic competition Age2 variable in class notes as an example. \n","\n","> Picking the right variables, cleaning them, and engineering good ones will take the most time/effort but they will increase your score more than anything. Consider a model without Gender variable for the Titanic competition. No matter how you tune your hyperparameters or engineer new variables, a model without Gender will highly likely do worse than a simple model with Gender. \n","\n","\n","## Hands-on Tasks\n","When you are ready with your variables, the next step is to create your model. You are asked to use the following methods to train your model and do predictions. You are also asked to fine-tune the hyperparameters. Follow the Titanic example for decision tree and random forests, and use either DataCamp notes, Kernels, or online sources to do the rest of the methods. Use gridsearch for tuning similar to Titanic example. XGboost is not covered in any of the assigned DataCamp courses, but there is course on it. You can look at the slides and videos to get started with it.\n","\n","**Model Training and Tuning**\n","* Decision Tree (no need to create the actual decision tree with graphviz)\n","* Random Forests\n","* Regularized linear regression - ridge\n","* Regularized linear regression - lasso\n","* XGboost\n","\n"]},{"metadata":{"id":"6qZLokUpjg_a","colab_type":"text"},"cell_type":"markdown","source":["I provided sample code to start you with the project. You can build on them to prepare your submission file. It is a (very) good idea to have multiple code cells, where each one does certain things, similar to the class notes on the Titanic competition."]},{"metadata":{"id":"V1xMk2Cr_CcK","colab_type":"code","colab":{}},"cell_type":"code","source":["# load the libraries\n","\n","# pandas\n","import pandas as pd\n","from pandas import Series,DataFrame\n","\n","# to download files from Colab to our computer\n","from google.colab import files\n","\n","# import GridSearchCV for fine-tuning\n","from sklearn.model_selection import GridSearchCV"],"execution_count":0,"outputs":[]},{"metadata":{"id":"u6-rFU-C3bo7","colab_type":"code","colab":{}},"cell_type":"code","source":["# load the data to dataframes\n","train_df = pd.read_csv(\"https://s3.amazonaws.com/it4ba/Kaggle/train.csv\")\n","test_df    = pd.read_csv(\"https://s3.amazonaws.com/it4ba/Kaggle/test.csv\")"],"execution_count":0,"outputs":[]},{"metadata":{"id":"1hXL4BEfkjdC","colab_type":"text"},"cell_type":"markdown","source":["Use your pandas skills for EDA, missing data, and feature engineering. This part will be very long and should show good amount of effort. There may be some outliers for certain variables as well. Look into how to dealing with them. \n","\n","Check out the  [data descriptions](https://www.kaggle.com/c/house-prices-advanced-regression-techniques/data) from Kaggle. Work on the variables that you think will affect the sale price (number of bedrooms vs. fence quality). Also, come up with creative new variables such as combining pool, fireplace, and garage variables, and marking houses with these features as luxurious."]},{"metadata":{"id":"fbvXuIrpkh2F","colab_type":"code","colab":{}},"cell_type":"code","source":["# get to know the data\n","train_df.info()"],"execution_count":0,"outputs":[]},{"metadata":{"id":"Z_t_LSqbucsj","colab_type":"code","outputId":"1bc76d25-94f6-4f93-cedc-9919e157faf0","executionInfo":{"status":"ok","timestamp":1544757324704,"user_tz":300,"elapsed":349,"user":{"displayName":"Phat T Tran","photoUrl":"","userId":"05526002729072716169"}},"colab":{"base_uri":"https://localhost:8080/","height":176}},"cell_type":"code","source":["# checking out year built variable...is there a difference between a house built in 1941 and in 1942? if yes, then keep it; if no, then treat it\n","train_df['YearBuilt'].describe()"],"execution_count":0,"outputs":[{"output_type":"execute_result","data":{"text/plain":["count    1460.000000\n","mean     1971.267808\n","std        30.202904\n","min      1872.000000\n","25%      1954.000000\n","50%      1973.000000\n","75%      2000.000000\n","max      2010.000000\n","Name: YearBuilt, dtype: float64"]},"metadata":{"tags":[]},"execution_count":5}]},{"metadata":{"id":"11FsJ1vSuvIz","colab_type":"code","outputId":"da4c9b67-ba69-4d54-e7dc-372c4c4a6b4f","executionInfo":{"status":"ok","timestamp":1544757327342,"user_tz":300,"elapsed":469,"user":{"displayName":"Phat T Tran","photoUrl":"","userId":"05526002729072716169"}},"colab":{"base_uri":"https://localhost:8080/","height":364}},"cell_type":"code","source":["# sale Price Histogram...seems like there are couple outliers (very expensive houses)\n","train_df['SalePrice'].plot.hist()"],"execution_count":0,"outputs":[{"output_type":"execute_result","data":{"text/plain":["<matplotlib.axes._subplots.AxesSubplot at 0x7f29a25b2550>"]},"metadata":{"tags":[]},"execution_count":6},{"output_type":"display_data","data":{"image/png":"iVBORw0KGgoAAAANSUhEUgAAAfIAAAFKCAYAAADmCN3IAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n","text/plain":["<matplotlib.figure.Figure at 0x7f29a46b6f60>"]},"metadata":{"tags":[]}}]},{"metadata":{"id":"SMR75saYu6KN","colab_type":"code","outputId":"e8af2fa1-9fe2-4ff8-f97b-47e4e310d686","executionInfo":{"status":"ok","timestamp":1544757328904,"user_tz":300,"elapsed":331,"user":{"displayName":"Phat T Tran","photoUrl":"","userId":"05526002729072716169"}},"colab":{"base_uri":"https://localhost:8080/","height":34}},"cell_type":"code","source":["# missing data on fireplace quality...but do we need this variable?\n","train_df['FireplaceQu'].isna().sum()"],"execution_count":0,"outputs":[{"output_type":"execute_result","data":{"text/plain":["690"]},"metadata":{"tags":[]},"execution_count":7}]},{"metadata":{"id":"C8kXGdHLqnzK","colab_type":"code","colab":{}},"cell_type":"code","source":["# build your model\n","# I decided that year built and overall quality are important determiners of the sale price.\n","X_train = train_df[[\"YearBuilt\", \"OverallQual\"]]\n","Y_train = train_df[\"SalePrice\"]\n","X_test  = test_df[[\"YearBuilt\", \"OverallQual\"]]\n"],"execution_count":0,"outputs":[]},{"metadata":{"id":"9x-Y1BOSkZT2","colab_type":"text"},"cell_type":"markdown","source":["The remaining part up to Kaggle score will be very similar and repeated for each method. Make sure to load the correct algorithms from scikit-learn in the first code cell below. Each algorithm has its own hyperparameters. You need to do some search to find out which ones are more common and likely to help and fine-tune them. Compare decision tree and random forests code in Titanic example in class notes and see where they differ. \n","\n","Don't forget to convert categorical variables to numeric variables. Refer to the class notes, first code cell of Machine Learning Methods, for an example of converting `Embarked` and `Sex` variables."]},{"metadata":{"id":"zqXqCn-gpo8b","colab_type":"text"},"cell_type":"markdown","source":["## 1. Decision Tree\n","[Write a paragraph on this method explaining what it is and how it works, when it works. Use your own words and have a technical/statistical tone aimed for a high level business executive. ] - you have to repeat this for all methods."]},{"metadata":{"id":"XrY3mrYOkYuX","colab_type":"code","colab":{}},"cell_type":"code","source":["# load decision tree method\n","from sklearn.tree import DecisionTreeClassifier"],"execution_count":0,"outputs":[]},{"metadata":{"id":"mwsZwrpR-98m","colab_type":"code","colab":{}},"cell_type":"code","source":["# train and predict \n","dt = DecisionTreeClassifier (random_state = 1)\n","\n","dt.fit(X_train, Y_train)\n","\n","# make your predictions\n","Y_pred = dt.predict(X_test)\n"],"execution_count":0,"outputs":[]},{"metadata":{"id":"kd-jrNf-1JhN","colab_type":"text"},"cell_type":"markdown","source":["This is where you do your fine-tuning with grid search. Look at the \"Fine Tuning Hyperparameters\" section in the Titanic example on class notes for code help"]},{"metadata":{"id":"YH_vokJOJ9KM","colab_type":"code","colab":{}},"cell_type":"code","source":["# Refer to the code in class notes and pick your hyperparameters and grid ranges."],"execution_count":0,"outputs":[]},{"metadata":{"id":"msmS-6yE-90i","colab_type":"code","colab":{}},"cell_type":"code","source":["# prepare a submission file\n","submission = pd.DataFrame({\n","        \"Id\": test_df[\"Id\"],\n","        \"SalePrice\": Y_pred\n","    })\n","submission.to_csv('dt1.csv', index=False)\n","\n","files.download('dt1.csv')"],"execution_count":0,"outputs":[]},{"metadata":{"id":"FKCCJZZqmvav","colab_type":"text"},"cell_type":"markdown","source":["---\n","\n","\n","**`Kaggle Score: 0.34990`**\n","\n","\n","---\n","<br/>"]},{"metadata":{"id":"BFN148XkAivY","colab_type":"text"},"cell_type":"markdown","source":["# Submission\n","\n","## First Submission of your project - due 12/10 11:59 pm\n","The first submission is to make sure you can run a basic model and you know how to submit a prediction to Kaggle. You will not be graded on your Kaggle score/ranking.\n","\n","After you submit a prediction to Kaggle and get your score, take a screenshot of it - showing your score and display name clearly. Upload the screenshot to Blackboard from the Project menu before the deadline. Do not change your display name (amy-xx) after this submission. This screenshot is the only way I can match Kaggle display names to student names in the class.\n","\n","> **If you miss the first submission, your Part 2 grade will be penalized. You can still do a final submission but with 50% deduction.**\n","\n","## Final Submission of your project - due 12/14 5:00pm\n","\n","Once you are done with the project:\n","1. name the colab notebook: Project - Your first and last name (Ex., Project - Tony Stark),\n","2. share the notebook with me and give me editing rights, not just viewing,\n","3. email me your best score.\n","\n","I should be able to replicate your prediction that gave you the best Kaggle score. I will run the code for the method with the best score on your notebook and submit its prediction to Kaggle. **My submission must generate your best score on Kaggle.** You will be ranked last if I cannot get your best Kaggle score after running your code.\n","\n","Do not make any submissions after sharing the notebook and emailing your final score until your final grades are posted. \n"]},{"metadata":{"id":"n0eD19thJwsx","colab_type":"text"},"cell_type":"markdown","source":["#Grading\n","\n","**Part 1: 3 points**  \n","This is 1.5 times of a homework so spend good amount of time explaining and give examples if neccesarry. Do not copy/paste, use your own words.\n","\n","<br/>\n","**Part 2 - effort: 5 points**\n","* Addressing missing data.\n","* Feature engineering: including creating new variables, transforming/grouping existing variables.\n","* Multiple submissions showing improvement of your prediction over time. Improvements can come from adding/removing/transforming variables, using different methods, fine tuning your method.\n","* Fine tuning hyperparameters, even if this leads to a worse prediction. \n","* Explanation of hyperparameters used in fine tuning the model.\n","* Explanation of each method (e.g., random forest).\n","* Description of what you are doing and why throughout the notebook. You shouldn't have pages of code and output without explanation. \n","* Notebook hygiene: remove non-working and unnecessary code and code cells, add comments to your code if necessary\n","\n","<br/>\n","**Part 2 - ranking: 10 points**  \n","* First place will get 10 points.   \n","* Last place will get 0 points.   \n","* The remaining students will get a grade between 0 and 10.  "]},{"metadata":{"id":"z5SEafNzZg4d","colab_type":"text"},"cell_type":"markdown","source":["# TL;DR\n","1. Answer the questions in Part 1.\n","2. Submit one of your predictions before **12/10 11:59 pm** and upload a screenshot to Blackboard.\n","3. Submit your best prediciton by **12/14 5:00 pm** and email your score."]}]}